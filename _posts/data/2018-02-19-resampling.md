---
layout: post
title:  "Resampling and Cross Validation"
author: Hai Lan
date: 2018-02-19
categories: data
tags: [AI,R]
use_math: true
comments: false
---

机器学习的目标（包括一般统计）常常见于两处：

1. 形成解释性模型，即，找到解释变量与响应变量之间的统计上的逻辑关系。比如金融上注明的三因子模型。所有的数据都用于训练模型。
2. 形成预测能力，即发现解释变量与响应变量之间的模式，在解释变量出现对应模式的时候，预测可能的响应输出。数据往往被分为训练数据和检验数据两个部分。训练数据用以发现模式，检验数据（因为包含有明确知道的响应变量的输出）用以检验模型是否有效。

对于前者，我们希望尽可能的发现存在的逻辑关系，使得不能被解释的响应变量的波动尽量的小。也就是说$R^2$尽量的大。相应的数据的MSE（Mean Squared Errors）尽量的小。但是，有因为统计拟合的原因，我们总是能够通过增加模型的自由度（增加解释变量）来获得更好的拟合，从而形成过拟合的现象。因此，我们在一面追寻MSE最小的同时，一面也控制自由度的增加。无论是AIC还是BIC方法，其核心都是在MES和自由度之间做取舍。

而对于后者，我们则需要一些技巧来处理。因为这个时候基于检验集合的MSE才是我们关心的内容，至于模型的自由度我们并不认为是一个要紧的问题。而计算检验集合的MSE并将其合理的最小化，我们总要有合适的方法来产生检验集合。我们常见的方法有：

# 定序采样

包括：

* 取一检验：在$1,\cdots,n$的原始数据中，一次以第$i$个数据为检验数据，其余为训练数据。好处是，训练数据最大化，因而估计的检验MSE几乎可以认为是无偏差的。但同时训练数据高度重合从而使得检验MSE是高度相关的序列，因此其估计的方差较大。
* k段检验： 方法与取一检验一样。只是将原始数据分为大小相同的k个段，依次取一段作为检验集合。该方法会产生一定的MSE估计偏差，但是对应的方差较小，从而整体上更优。通常k取5或者10.

# 随机采样

用随机的方法确定采样集合。

当然，并不是说AIC或者BIC之类的方法不能用于预测模型的选择。事实上，无论$C_p$,AIC还是BIC都是对于训练集集MSE的修正，从而使得它们更接近与检验集的MSE。例如$C_p$，其计算公式是：

$$
C_p = \frac{1}{n}(RSS + 2d\hat{\sigma}^2)
$$

其中$\hat{\sigma}^2$是残差的方差的估计。可以证明，当$\hat{\sigma}^2$是无偏估计的时候，$C_p$是检验集的MSE的无偏估计。因此，寻找最小的$C_p$，成为可行的选择模型的方法。AIC的计算方法跟$C_p$很类似，

$$
AIC = \frac{1}{n\hat{\sigma}^2}(RSS + 2d\hat{\sigma}^2)
$$

至于BIC则是来自于Bayesian学派的估计，往往是有偏差的，往往也是bias-varriance平衡处理的比较好的。

$$
BIC = \frac{1}{n}(RSS + \log (n) d\hat{\sigma}^2)
$$

往往BIC加重了对于大的d（解释变量的数目）的惩罚力度，因此最小BIC选出的模型相对于最小$C_p$或者AIC选出的模型，解释变量数目可能要偏少一些。

至于很多统计软件都生成的修正的$R^2$(adjusted $R^2$)，逻辑要简单很多，以归结到F分布的方式修正$R^2$。其数学定义是：

$$
adjusted\ \ \ R^2 = 1- \frac{\frac{RSS}{n-d-1}}{\frac{TSS}{n-1}}
$$

但是，无论$C_p$，AIC还是BIC，又或者是统计理论支持稍差一些的修正$R^2$都比不得直接验算检验集的MSE应用的范围更广。
